{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/data/spark-2.2.3-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName(\"Word Conut\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF,Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-----+\n",
      "| id|            text|label|\n",
      "+---+----------------+-----+\n",
      "|  0| a b c d e spark|  1.0|\n",
      "|  1|             b d|  0.0|\n",
      "|  2|     spark f g h|  1.0|\n",
      "|  3|hadoop mapreduce|  0.0|\n",
      "+---+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义\n",
    "tokenizer = Tokenizer(inputCol=\"text\",outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol =tokenizer.getOutputCol(),outputCol = \"features\")\n",
    "lr = LogisticRegression(maxIter=10,regParam=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,hashingTF,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"spark hadoop spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|              text|\n",
      "+---+------------------+\n",
      "|  4|       spark i j k|\n",
      "|  5|             l m n|\n",
      "|  6|spark hadoop spark|\n",
      "|  7|     apache hadoop|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| id|              text|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+---+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  4|       spark i j k|    [spark, i, j, k]|(262144,[20197,24...|[-1.6609033227472...|[0.15964077387874...|       1.0|\n",
      "|  5|             l m n|           [l, m, n]|(262144,[18910,10...|[1.64218895265644...|[0.83783256854767...|       0.0|\n",
      "|  6|spark hadoop spark|[spark, hadoop, s...|(262144,[155117,2...|[-2.5980142174393...|[0.06926633132976...|       1.0|\n",
      "|  7|     apache hadoop|    [apache, hadoop]|(262144,[66695,15...|[4.00817033336812...|[0.98215753334442...|       0.0|\n",
      "+---+------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, spark i j k) --> prob=[0.1596407738787475,0.8403592261212525], prediction=1.000000\n",
      "(5, l m n) --> prob=[0.8378325685476744,0.16216743145232562], prediction=0.000000\n",
      "(6, spark hadoop spark) --> prob=[0.06926633132976037,0.9307336686702395], prediction=1.000000\n",
      "(7, apache hadoop) --> prob=[0.9821575333444218,0.01784246665557808], prediction=0.000000\n"
     ]
    }
   ],
   "source": [
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    rid, text, prob, prediction = row\n",
    "    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector,Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer,VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文本\n",
    "def load(x):\n",
    "    rel = {}\n",
    "    rel['features'] = Vectors.dense(float(x[0]),float(x[1]),float(x[3]))\n",
    "    rel['label'] = str(x[4])\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sparkContext.textFile('iris.txt').map(lambda x:x.split(',')).map(lambda p:Row(**load(p))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([5.1, 3.5, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.9, 3.0, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.7, 3.2, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.6, 3.1, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([5.0, 3.6, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([5.4, 3.9, 0.4]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.6, 3.4, 0.3]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([5.0, 3.4, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.4, 2.9, 0.2]), label='Iris-setosa'),\n",
       " Row(features=DenseVector([4.9, 3.1, 0.1]), label='Iris-setosa')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql('select * from iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|     features|      label|\n",
      "+-------------+-----------+\n",
      "|[5.1,3.5,0.2]|Iris-setosa|\n",
      "|[4.9,3.0,0.2]|Iris-setosa|\n",
      "|[4.7,3.2,0.2]|Iris-setosa|\n",
      "|[4.6,3.1,0.2]|Iris-setosa|\n",
      "|[5.0,3.6,0.2]|Iris-setosa|\n",
      "|[5.4,3.9,0.4]|Iris-setosa|\n",
      "|[4.6,3.4,0.3]|Iris-setosa|\n",
      "|[5.0,3.4,0.2]|Iris-setosa|\n",
      "|[4.4,2.9,0.2]|Iris-setosa|\n",
      "|[4.9,3.1,0.1]|Iris-setosa|\n",
      "|[5.4,3.7,0.2]|Iris-setosa|\n",
      "|[4.8,3.4,0.2]|Iris-setosa|\n",
      "|[4.8,3.0,0.1]|Iris-setosa|\n",
      "|[4.3,3.0,0.1]|Iris-setosa|\n",
      "|[5.8,4.0,0.2]|Iris-setosa|\n",
      "|[5.7,4.4,0.4]|Iris-setosa|\n",
      "|[5.4,3.9,0.4]|Iris-setosa|\n",
      "|[5.1,3.5,0.3]|Iris-setosa|\n",
      "|[5.7,3.8,0.3]|Iris-setosa|\n",
      "|[5.1,3.8,0.3]|Iris-setosa|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = df.rdd.map(lambda t:str(t[1])+':'+str(t[0])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa:[5.1,3.5,0.2]\n"
     ]
    }
   ],
   "source": [
    "for i in rel:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征处理,进行索引，并进行重新命名\n",
    "labelindexer = StringIndexer(inputCol='label',outputCol='indexedlabel').fit(df)\n",
    "featureindexer = VectorIndexer(inputCol='features',outputCol='indexedfeatures',maxCategories=4).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelconverter = IndexToString(inputCol='prediction',outputCol='predictedlabel',labels=labelindexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "from pyspark.ml.classification import DecisionTreeClassificationModel,DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='indexedlabel',featuresCol='indexedfeatures')\n",
    "pipelineclassifier = Pipeline(stages=[labelindexer,featureindexer,dt,labelconverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipelineclassifier.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+------------+---------------+--------------+--------------------+----------+---------------+\n",
      "|     features|          label|indexedlabel|indexedfeatures| rawPrediction|         probability|prediction| predictedlabel|\n",
      "+-------------+---------------+------------+---------------+--------------+--------------------+----------+---------------+\n",
      "|[4.4,3.2,0.2]|    Iris-setosa|         0.0|  [4.4,3.2,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[4.6,3.1,0.2]|    Iris-setosa|         0.0|  [4.6,3.1,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[4.8,3.4,0.2]|    Iris-setosa|         0.0|  [4.8,3.4,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[4.9,2.4,1.0]|Iris-versicolor|         1.0|  [4.9,2.4,1.0]| [0.0,0.0,1.0]|       [0.0,0.0,1.0]|       2.0| Iris-virginica|\n",
      "|[5.0,3.0,0.2]|    Iris-setosa|         0.0|  [5.0,3.0,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.0,3.3,0.2]|    Iris-setosa|         0.0|  [5.0,3.3,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.1,2.5,1.1]|Iris-versicolor|         1.0|  [5.1,2.5,1.1]|[0.0,34.0,2.0]|[0.0,0.9444444444...|       1.0|Iris-versicolor|\n",
      "|[5.1,3.7,0.4]|    Iris-setosa|         0.0|  [5.1,3.7,0.4]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.1,3.8,0.2]|    Iris-setosa|         0.0|  [5.1,3.8,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.3,3.7,0.2]|    Iris-setosa|         0.0|  [5.3,3.7,0.2]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.4,3.0,1.5]|Iris-versicolor|         1.0|  [5.4,3.0,1.5]|[0.0,34.0,2.0]|[0.0,0.9444444444...|       1.0|Iris-versicolor|\n",
      "|[5.4,3.9,0.4]|    Iris-setosa|         0.0|  [5.4,3.9,0.4]|[41.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|    Iris-setosa|\n",
      "|[5.6,2.8,2.0]| Iris-virginica|         2.0|  [5.6,2.8,2.0]| [0.0,0.0,3.0]|       [0.0,0.0,1.0]|       2.0| Iris-virginica|\n",
      "|[5.6,3.0,1.5]|Iris-versicolor|         1.0|  [5.6,3.0,1.5]|[0.0,34.0,2.0]|[0.0,0.9444444444...|       1.0|Iris-versicolor|\n",
      "|[5.7,2.6,1.0]|Iris-versicolor|         1.0|  [5.7,2.6,1.0]|[0.0,34.0,2.0]|[0.0,0.9444444444...|       1.0|Iris-versicolor|\n",
      "|[5.7,2.8,1.3]|Iris-versicolor|         1.0|  [5.7,2.8,1.3]|[0.0,34.0,2.0]|[0.0,0.9444444444...|       1.0|Iris-versicolor|\n",
      "|[5.8,2.8,2.4]| Iris-virginica|         2.0|  [5.8,2.8,2.4]| [0.0,0.0,3.0]|       [0.0,0.0,1.0]|       2.0| Iris-virginica|\n",
      "|[5.9,3.0,1.8]| Iris-virginica|         2.0|  [5.9,3.0,1.8]| [0.0,1.0,0.0]|       [0.0,1.0,0.0]|       1.0|Iris-versicolor|\n",
      "|[6.0,2.2,1.0]|Iris-versicolor|         1.0|  [6.0,2.2,1.0]| [0.0,1.0,1.0]|       [0.0,0.5,0.5]|       1.0|Iris-versicolor|\n",
      "|[6.0,3.0,1.8]| Iris-virginica|         2.0|  [6.0,3.0,1.8]|[0.0,0.0,22.0]|       [0.0,0.0,1.0]|       2.0| Iris-virginica|\n",
      "+-------------+---------------+------------+---------------+--------------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedlabel',predictionCol='prediction',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302325581395349"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_483e85f3950da3e9d761) of depth 5 with 15 nodes\n",
      "  If (feature 2 <= 0.6)\n",
      "   Predict: 0.0\n",
      "  Else (feature 2 > 0.6)\n",
      "   If (feature 2 <= 1.7)\n",
      "    If (feature 0 <= 4.9)\n",
      "     Predict: 2.0\n",
      "    Else (feature 0 > 4.9)\n",
      "     If (feature 0 <= 6.9)\n",
      "      If (feature 1 <= 2.2)\n",
      "       Predict: 1.0\n",
      "      Else (feature 1 > 2.2)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 6.9)\n",
      "      Predict: 2.0\n",
      "   Else (feature 2 > 1.7)\n",
      "    If (feature 0 <= 5.9)\n",
      "     If (feature 0 <= 5.8)\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 > 5.8)\n",
      "      Predict: 1.0\n",
      "    Else (feature 0 > 5.9)\n",
      "     Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector,Vectors\n",
    "from pyspark.ml.feature import HashingTF,Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n",
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().setLabelCol(\"indexedlabel\").setFeaturesCol(\"indexedfeatures\").setMaxIter(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPipeline = Pipeline().setStages([labelindexer, featureindexer, lr, labelconverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parmgrid = ParamGridBuilder().addGrid(lr.elasticNetParam,[0.2,0.8]).addGrid(lr.regParam,[0.01,0.1,0.5]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=lrPipeline,\n",
    "                    evaluator=MulticlassClassificationEvaluator(labelCol='indexedlabel',predictionCol='prediction'),\n",
    "                    estimatorParamMaps=parmgrid).setNumFolds(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvmodel = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+------------+---------------+--------------------+--------------------+----------+---------------+\n",
      "|     features|          label|indexedlabel|indexedfeatures|       rawPrediction|         probability|prediction| predictedlabel|\n",
      "+-------------+---------------+------------+---------------+--------------------+--------------------+----------+---------------+\n",
      "|[4.4,3.2,0.2]|    Iris-setosa|         0.0|  [4.4,3.2,0.2]|[4.54394107622339...|[0.98017154548802...|       0.0|    Iris-setosa|\n",
      "|[4.6,3.1,0.2]|    Iris-setosa|         0.0|  [4.6,3.1,0.2]|[4.00585057313672...|[0.95891326011930...|       0.0|    Iris-setosa|\n",
      "|[4.8,3.4,0.2]|    Iris-setosa|         0.0|  [4.8,3.4,0.2]|[4.70687210796738...|[0.98116452730350...|       0.0|    Iris-setosa|\n",
      "|[4.9,2.4,1.0]|Iris-versicolor|         1.0|  [4.9,2.4,1.0]|[-0.7688384702878...|[0.10593707233481...|       1.0|Iris-versicolor|\n",
      "|[5.0,3.0,0.2]|    Iris-setosa|         0.0|  [5.0,3.0,0.2]|[3.23944757644271...|[0.88467563680563...|       0.0|    Iris-setosa|\n",
      "|[5.0,3.3,0.2]|    Iris-setosa|         0.0|  [5.0,3.3,0.2]|[4.16878160488070...|[0.96092995900496...|       0.0|    Iris-setosa|\n",
      "|[5.1,2.5,1.1]|Iris-versicolor|         1.0|  [5.1,2.5,1.1]|[-0.9703447339981...|[0.08517281744937...|       1.0|Iris-versicolor|\n",
      "|[5.1,3.7,0.4]|    Iris-setosa|         0.0|  [5.1,3.7,0.4]|[4.72779383682980...|[0.98368844776514...|       0.0|    Iris-setosa|\n",
      "|[5.1,3.8,0.2]|    Iris-setosa|         0.0|  [5.1,3.8,0.2]|[5.6035154054737,...|[0.99305616072603...|       0.0|    Iris-setosa|\n",
      "|[5.3,3.7,0.2]|    Iris-setosa|         0.0|  [5.3,3.7,0.2]|[5.06542490238702...|[0.98540708314558...|       0.0|    Iris-setosa|\n",
      "|[5.4,3.0,1.5]|Iris-versicolor|         1.0|  [5.4,3.0,1.5]|[-0.8958105453416...|[0.11114083650112...|       1.0|Iris-versicolor|\n",
      "|[5.4,3.9,0.4]|    Iris-setosa|         0.0|  [5.4,3.9,0.4]|[5.00488111537745...|[0.98704010712600...|       0.0|    Iris-setosa|\n",
      "|[5.6,2.8,2.0]| Iris-virginica|         2.0|  [5.6,2.8,2.0]|[-3.1585379558190...|[0.00233036579439...|       2.0| Iris-virginica|\n",
      "|[5.6,3.0,1.5]|Iris-versicolor|         1.0|  [5.6,3.0,1.5]|[-1.1241230389489...|[0.08061751028981...|       1.0|Iris-versicolor|\n",
      "|[5.7,2.6,1.0]|Iris-versicolor|         1.0|  [5.7,2.6,1.0]|[-1.0625324257585...|[0.05984508819868...|       1.0|Iris-versicolor|\n",
      "|[5.7,2.8,1.3]|Iris-versicolor|         1.0|  [5.7,2.8,1.3]|[-1.2918917455467...|[0.05712485197973...|       1.0|Iris-versicolor|\n",
      "|[5.8,2.8,2.4]| Iris-virginica|         2.0|  [5.8,2.8,2.4]|[-4.5187375677555...|[1.06221338521630...|       2.0| Iris-virginica|\n",
      "|[5.9,3.0,1.8]| Iris-virginica|         2.0|  [5.9,3.0,1.8]|[-2.3155071181068...|[0.01370996651364...|       2.0| Iris-virginica|\n",
      "|[6.0,2.2,1.0]|Iris-versicolor|         1.0|  [6.0,2.2,1.0]|[-2.6441132040868...|[0.00710526770619...|       1.0|Iris-versicolor|\n",
      "|[6.0,3.0,1.8]| Iris-virginica|         2.0|  [6.0,3.0,1.8]|[-2.4296633649104...|[0.01155856886488...|       2.0| Iris-virginica|\n",
      "+-------------+---------------+------------+---------------+--------------------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_1 = cvmodel.transform(test)\n",
    "pred_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302325581395349"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = cvmodel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = bestmodel.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(3, 3, [-1.1416, 3.0978, -2.8297, 0.6692, -0.7847, -0.4548, 0.5291, -3.0196, 4.3806], 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.coefficientMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.numClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regParam: regularization parameter (>= 0). (default: 0.0)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.explainParam(lr.regParam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
